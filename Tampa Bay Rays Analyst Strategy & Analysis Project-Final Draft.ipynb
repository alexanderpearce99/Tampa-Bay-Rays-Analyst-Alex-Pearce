{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    " \n",
    "from sklearn.linear_model import LassoCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data exploration\n",
    "\n",
    "def dataexploration(df):\n",
    "    #Store na values in separate dataframe, and then drop them from primary dataset\n",
    "    null_df = df.isnull()\n",
    "    rows_has_na = null_df.any(axis = 1)\n",
    "    rows_with_na = df[rows_has_na]\n",
    "    df = df.dropna(axis=0)\n",
    "    #Calculate Summary Statistics for Numerical and Binary Variables\n",
    "    print(df[['home_win_pct', 'away_win_pct', 'temp', 'pct_season_completed', 'is_bobblehead', 'attendance']].describe())\n",
    "    #Histogram to Look at Distribution of Attendance Variable\n",
    "    df_histogram = df.hist(column='attendance', bins = 5)\n",
    "    print(df_histogram)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression model\n",
    "\n",
    "def linearregression(df):\n",
    "    #Make sure to turn categorical variables into binary variables for regression + run regression model\n",
    "    fit = ols('attendance ~ home_win_pct + away_win_pct + C(opposing_team) + C(day_of_week_effect) + temp + pct_season_completed + is_bobblehead', data = df).fit()\n",
    "    \n",
    "    linear = fit.summary()\n",
    "    \n",
    "    return linear\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummy variables from categorical variables\n",
    "def dummies(df):\n",
    "     #Create dummy variables from categorical variables\n",
    "    dummies = pd.get_dummies(df, columns=['opposing_team', 'day_of_week_effect'])\n",
    "    #Drop one value from each set of dummy variables\n",
    "    dummies = dummies.drop(['opposing_team_1', 'day_of_week_effect_1'], axis=1)\n",
    "    #Create dependent variable dataframe\n",
    "    Y = dummies['attendance']\n",
    "    #Drop attendance from explanatory variable dataframe\n",
    "    X = dummies.drop(['attendance'], axis=1)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge regression model\n",
    "def ridge(X,Y):\n",
    "    #Determine optimal value for alpha in 10-fold cross-validation Ridge regression\n",
    "    model = RidgeCV(alphas = np.arange(0.01,10,0.01), cv=10)\n",
    "    model.fit(X, Y)\n",
    "    #Use best lambda value in final ridge regrssion\n",
    "    final_ridge = Ridge(alpha=model.alpha_)\n",
    "    final_ridge.fit(X, Y)    \n",
    "    return model, final_ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LASSO regression model\n",
    "def lasso(X,Y):\n",
    "    #Determine optimal value for alpha in 10-fold cross-validation LASSO regression\n",
    "    model = LassoCV(cv=10, random_state=0, max_iter=10000)\n",
    "    model.fit(X, Y)\n",
    "    #Use best alpha value in final LASSO regrssion\n",
    "    final_lasso = Lasso(alpha=model.alpha_)\n",
    "    final_lasso.fit(X, Y)   \n",
    "    return model, final_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       home_win_pct  away_win_pct        temp  pct_season_completed  \\\n",
      "count    810.000000    810.000000  810.000000            810.000000   \n",
      "mean       0.016073      0.030918    0.012921              0.499375   \n",
      "std        0.979720      0.993248    1.001152              0.288679   \n",
      "min       -2.809775     -2.695329   -2.917976              0.000863   \n",
      "25%       -0.606891     -0.660149   -0.639705              0.255120   \n",
      "50%        0.019855      0.054645   -0.034318              0.495445   \n",
      "75%        0.663517      0.668634    0.680898              0.747405   \n",
      "max        3.241040      3.390371    3.421095              0.997738   \n",
      "\n",
      "       is_bobblehead    attendance  \n",
      "count     810.000000    810.000000  \n",
      "mean        0.096296  28034.881481  \n",
      "std         0.295179   5854.629167  \n",
      "min         0.000000   9761.000000  \n",
      "25%         0.000000  24055.000000  \n",
      "50%         0.000000  27846.000000  \n",
      "75%         0.000000  31933.500000  \n",
      "max         1.000000  47136.000000  \n",
      "[[<matplotlib.axes._subplots.AxesSubplot object at 0x1a24f7f850>]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load dataset, main function\n",
    "\n",
    "df = pd.read_csv('data_for_exercise.csv')\n",
    "\n",
    "df.drop('Unnamed: 0', axis = 1, inplace= True)\n",
    "\n",
    "\n",
    "def main(df):\n",
    "    dataexploration(df)\n",
    "    linear = linearregression(df)\n",
    "    X, Y = dummies(df)\n",
    "    model_ridge, final_ridge = ridge(X,Y)\n",
    "    model_lasso, final_lasso = lasso(X,Y)    \n",
    "    return linear, X, Y, model_ridge, final_ridge, model_lasso, final_lasso\n",
    "\n",
    "linear, X, Y, model_ridge, final_ridge, model_lasso, final_lasso = main(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             attendance   R-squared:                       0.896\n",
      "Model:                            OLS   Adj. R-squared:                  0.891\n",
      "Method:                 Least Squares   F-statistic:                     170.7\n",
      "Date:                Wed, 29 Jun 2022   Prob (F-statistic):               0.00\n",
      "Time:                        21:19:10   Log-Likelihood:                -7257.7\n",
      "No. Observations:                 810   AIC:                         1.460e+04\n",
      "Df Residuals:                     770   BIC:                         1.478e+04\n",
      "Df Model:                          39                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                   2.951e+04    403.816     73.082      0.000    2.87e+04    3.03e+04\n",
      "C(opposing_team)[T.2]       5365.7167    507.719     10.568      0.000    4369.039    6362.395\n",
      "C(opposing_team)[T.3]       3717.3734    528.602      7.032      0.000    2679.702    4755.045\n",
      "C(opposing_team)[T.4]       3890.5424    494.426      7.869      0.000    2919.960    4861.125\n",
      "C(opposing_team)[T.5]       4469.9723    485.797      9.201      0.000    3516.329    5423.616\n",
      "C(opposing_team)[T.6]        -17.1009    507.099     -0.034      0.973   -1012.561     978.359\n",
      "C(opposing_team)[T.7]       1013.6803    541.943      1.870      0.062     -50.180    2077.540\n",
      "C(opposing_team)[T.8]       -429.4031    509.067     -0.844      0.399   -1428.726     569.920\n",
      "C(opposing_team)[T.9]        157.3951    490.049      0.321      0.748    -804.595    1119.386\n",
      "C(opposing_team)[T.10]       353.4114    527.964      0.669      0.503    -683.008    1389.831\n",
      "C(opposing_team)[T.11]       633.8378    542.585      1.168      0.243    -431.283    1698.959\n",
      "C(opposing_team)[T.12]      -294.5999    521.641     -0.565      0.572   -1318.607     729.407\n",
      "C(opposing_team)[T.13]       313.6704    488.773      0.642      0.521    -645.815    1273.156\n",
      "C(opposing_team)[T.14]      1096.2384    544.334      2.014      0.044      27.683    2164.793\n",
      "C(opposing_team)[T.15]       245.4183    492.262      0.499      0.618    -720.917    1211.754\n",
      "C(opposing_team)[T.16]       833.0800    553.254      1.506      0.133    -252.985    1919.145\n",
      "C(opposing_team)[T.17]       355.6353    480.631      0.740      0.460    -587.866    1299.137\n",
      "C(opposing_team)[T.18]        -9.9473    489.402     -0.020      0.984    -970.668     950.773\n",
      "C(opposing_team)[T.19]       799.6809    548.690      1.457      0.145    -277.424    1876.786\n",
      "C(opposing_team)[T.20]       492.0154    511.641      0.962      0.337    -512.362    1496.392\n",
      "C(opposing_team)[T.21]      -439.1653    529.883     -0.829      0.407   -1479.351     601.021\n",
      "C(opposing_team)[T.22]       332.7114    534.492      0.622      0.534    -716.522    1381.945\n",
      "C(opposing_team)[T.23]       818.0775    533.597      1.533      0.126    -229.400    1865.555\n",
      "C(opposing_team)[T.24]       435.8551    501.130      0.870      0.385    -547.888    1419.599\n",
      "C(opposing_team)[T.25]        18.5644    483.884      0.038      0.969    -931.324     968.453\n",
      "C(opposing_team)[T.26]       376.3732    518.660      0.726      0.468    -641.782    1394.529\n",
      "C(opposing_team)[T.27]       -72.1067    478.959     -0.151      0.880   -1012.328     868.114\n",
      "C(opposing_team)[T.28]       747.4002    479.672      1.558      0.120    -194.219    1689.019\n",
      "C(opposing_team)[T.29]      1227.8604    497.424      2.468      0.014     251.392    2204.329\n",
      "C(day_of_week_effect)[T.2] -8000.1817    259.344    -30.848      0.000   -8509.286   -7491.077\n",
      "C(day_of_week_effect)[T.3] -6953.8115    254.585    -27.314      0.000   -7453.574   -6454.049\n",
      "C(day_of_week_effect)[T.4] -5238.6013    263.636    -19.871      0.000   -5756.131   -4721.072\n",
      "C(day_of_week_effect)[T.5] -3364.4357    253.829    -13.255      0.000   -3862.715   -2866.157\n",
      "C(day_of_week_effect)[T.6]   158.9856    259.871      0.612      0.541    -351.155     669.126\n",
      "C(day_of_week_effect)[T.7]  2070.7791    280.881      7.372      0.000    1519.396    2622.162\n",
      "home_win_pct                3962.0101     70.806     55.956      0.000    3823.015    4101.005\n",
      "away_win_pct                1557.4858     70.189     22.190      0.000    1419.701    1695.270\n",
      "temp                        -131.0499     69.006     -1.899      0.058    -266.512       4.412\n",
      "pct_season_completed        1558.0919    239.260      6.512      0.000    1088.412    2027.772\n",
      "is_bobblehead                -34.0462    237.112     -0.144      0.886    -499.508     431.416\n",
      "==============================================================================\n",
      "Omnibus:                        6.615   Durbin-Watson:                   2.079\n",
      "Prob(Omnibus):                  0.037   Jarque-Bera (JB):                7.272\n",
      "Skew:                           0.142   Prob(JB):                       0.0264\n",
      "Kurtosis:                       3.367   Cond. No.                         33.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#linear regression results\n",
    "\n",
    "print(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal lambda for Ridge is: 0.34\n",
      "\n",
      "Slope coefficients, and their corresponding variables, for Ridge regression are:\n",
      "\n",
      "[(3962.0579183362406, 'home_win_pct'), (1555.0708403488889, 'away_win_pct'), (-131.56964308141633, 'temp'), (1552.0089762983378, 'pct_season_completed'), (-38.89604026967215, 'is_bobblehead'), (5079.853120515567, 'opposing_team_2'), (3448.1768829041216, 'opposing_team_3'), (3633.297248026766, 'opposing_team_4'), (4218.210418766256, 'opposing_team_5'), (-231.58561954631432, 'opposing_team_6'), (779.4356298234078, 'opposing_team_7'), (-645.3297510317062, 'opposing_team_8'), (-50.17161974289533, 'opposing_team_9'), (136.79814832931842, 'opposing_team_10'), (403.02319942405165, 'opposing_team_11'), (-509.5284869760396, 'opposing_team_12'), (95.41562918533064, 'opposing_team_13'), (852.0154219916445, 'opposing_team_14'), (26.602923067112616, 'opposing_team_15'), (601.142786019412, 'opposing_team_16'), (135.5428404347691, 'opposing_team_17'), (-227.10088216839947, 'opposing_team_18'), (576.9085295045884, 'opposing_team_19'), (272.83708013897456, 'opposing_team_20'), (-660.4741010445094, 'opposing_team_21'), (115.69133126707581, 'opposing_team_22'), (586.6331417921602, 'opposing_team_23'), (216.20180981888328, 'opposing_team_24'), (-196.9106219245549, 'opposing_team_25'), (152.08227285171765, 'opposing_team_26'), (-290.6442844971697, 'opposing_team_27'), (518.8841384209522, 'opposing_team_28'), (998.7431537199112, 'opposing_team_29'), (-7913.195971916123, 'day_of_week_effect_2'), (-6871.2295986342915, 'day_of_week_effect_3'), (-5155.090628739473, 'day_of_week_effect_4'), (-3298.7972905154306, 'day_of_week_effect_5'), (223.82914874493724, 'day_of_week_effect_6'), (2134.104840993067, 'day_of_week_effect_7')]\n",
      "\n",
      "R squared for Ridge: 0.896\n"
     ]
    }
   ],
   "source": [
    "#ridge regression results\n",
    "\n",
    "print('Optimal lambda for Ridge is:', model_ridge.alpha_)\n",
    "\n",
    "print ('')\n",
    "\n",
    "print('Slope coefficients, and their corresponding variables, for Ridge regression are:')\n",
    "\n",
    "print('')\n",
    "\n",
    "print(list(zip(final_ridge.coef_, X)))\n",
    "\n",
    "print('')\n",
    "\n",
    "print('R squared for Ridge:', round(final_ridge.score(X, Y), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal lambda for Lasso is: 6.383656131149376\n",
      "\n",
      "Slope coefficients, and their corresponding variables, for Lasso regression are:\n",
      "\n",
      "[(3962.280261732839, 'home_win_pct'), (1538.2332026884653, 'away_win_pct'), (-121.51139531767568, 'temp'), (1454.560697942211, 'pct_season_completed'), (-0.0, 'is_bobblehead'), (4777.783897873623, 'opposing_team_2'), (3110.0610921503253, 'opposing_team_3'), (3337.2687515378875, 'opposing_team_4'), (3941.482436867295, 'opposing_team_5'), (-225.5468679811387, 'opposing_team_6'), (389.78434039782843, 'opposing_team_7'), (-638.4647467054193, 'opposing_team_8'), (-57.92869226894912, 'opposing_team_9'), (-0.0, 'opposing_team_10'), (0.0, 'opposing_team_11'), (-497.94265977395787, 'opposing_team_12'), (-0.0, 'opposing_team_13'), (437.07058004371567, 'opposing_team_14'), (-0.0, 'opposing_team_15'), (186.1650439561987, 'opposing_team_16'), (-0.0, 'opposing_team_17'), (-230.11827194712447, 'opposing_team_18'), (156.87209142935848, 'opposing_team_19'), (0.0, 'opposing_team_20'), (-626.5243278051821, 'opposing_team_21'), (-0.0, 'opposing_team_22'), (182.31876047814637, 'opposing_team_23'), (0.0, 'opposing_team_24'), (-205.8603573129118, 'opposing_team_25'), (-0.0, 'opposing_team_26'), (-309.5592673448217, 'opposing_team_27'), (206.3481374879026, 'opposing_team_28'), (665.9218943356999, 'opposing_team_29'), (-7849.369814985928, 'day_of_week_effect_2'), (-6815.071643113049, 'day_of_week_effect_3'), (-5074.369947931807, 'day_of_week_effect_4'), (-3242.7675002592855, 'day_of_week_effect_5'), (226.11105226607978, 'day_of_week_effect_6'), (2114.644464924728, 'day_of_week_effect_7')]\n",
      "\n",
      "R squared for Lasso: 0.895\n"
     ]
    }
   ],
   "source": [
    "#lasso regression results\n",
    "\n",
    "print('Optimal lambda for Lasso is:', model_lasso.alpha_)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Slope coefficients, and their corresponding variables, for Lasso regression are:')\n",
    "\n",
    "print('')\n",
    "\n",
    "print(list(zip(final_lasso.coef_, X)))\n",
    "\n",
    "print('')\n",
    "\n",
    "print('R squared for Lasso:', round(final_lasso.score(X, Y), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "\n",
    "The key algorithmic differences between the three models lie within their loss function, which is defined as how much variation there is in the response variable that is left unexplained by the model. A standard linear regression’s loss function is simply the sum of squared residuals – for each observation, the difference between the actual value of the response variable and the predicted value squared, all summed together. On the other hand, both the Ridge regression and LASSO regression introduce a penalty term that ultimately increases the model's bias, but decreases variance. For LASSO, the general idea is to shrink the coefficients in the linear model towards the central point as the mean. The Lasso loss function is equal to the sum of squared residuals plus a term of lambda (the penalty term that denotes the amount of shrinkage that will be implemented in the equation) multiplied by the sum of all the absolute values of the coefficients. The Ridge regression’s loss function is the same as the LASSO regression’s, except lambda is multiplied by the sum of all the squared values of the coefficients. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2:\n",
    "\n",
    "I believe that the LASSO regression model makes the best prediction. While all three models have the same R2 value of 0.896 (an R2 value is defined as the proportion of the variation in the dependent variable that is predictable from the independent variables in the model), both the Ridge regression model and LASSO regression model help address concerns of multicollinearty and overfitting. With many of the independent variables in the model being binary variables that represent different values of opposing_team and day_of_week_effect, the linear regression model suffers from concerns of multicollinearity. Ultimately, I believe that the LASSO regression model is better than the Ridge regression model because the LASSO regression removes less important variables from the model by shrinking their slope coefficients to zero. This creates a simpler model, and also addresses overfitting concerns, allowing for more accurate and useful predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3:\n",
    "    \n",
    "To determine which variables have the strongest effect on attendance, I looked at the magnitude of the slope coefficients, and most importantly, the T statistics, representing statistical significance. With a very large and dominating T statistic of 55.96 in the standard linear model, it strongly suggests that home win percent is the most important variable towards predicting attendance. Away win percent is also very important, with a T statistic of 22.19. The day of the week also is an important predictor of attendance, as days 2,3,4, and 5 all have T statistics with high absolute values and slope coefficients that are highly negative (significantly low attendance). While most of the T statistics for the binary variables representing different opposing teams are relatively low in magnitude, teams labeled 2,3,4, and 5 have a large statistically significant positive effect on attendance. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
